# This code imposed by the task of making Thread\ProcessPoolExecutor
# which will not workout all tasks at once, but will put results in
# some sort of Queue with maximum entries N.
#
# For example, the problem of generating N batches in advance to be
# supplied in fit_generator. You have infinite batches that can be
# generated by Augmentation, but you don't need more than N.
# Even though submitted tasks will be handled by K threads, they
# are submitted and it is a problem. We want to consume not more
# then N tasks at time.
#
# Related code also can be found in keras\utils\data_utils:
# SequenceEnqueuer, OrderEnqueuer and GenerateEnqueuer.
from time import sleep
import random
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor
import multiprocessing
import threading
from queue import Queue


def func_to_process(work_num):
    print('Work #{} started'.format(work_num))
    sleep(random.randint(1, 3))
    print('Work #{} done'.format(work_num))
    return work_num


if __name__ == '__main__':
    results_queue = Queue(maxsize=4)
    wrapper = lambda x: results_queue.put(func_to_process(x))

    with ThreadPoolExecutor(3) as executor:
        executor.map(wrapper, range(15))

        for i in range(15):
            sleep(5)
            res = results_queue.get(block=True)
            print('Popped result of job #{}'.format(res))


def problem_submit():
    with ProcessPoolExecutor(3) as executor:
        for i in range(100):
            executor.submit(func_to_process, i)
            print('Work #{} submitted'.format(i))


def problem_map():
    with ProcessPoolExecutor(3) as executor:
        executor.map(func_to_process, range(100))
        print('All works submitted')


def solution_submit_1():
    # https://github.com/mowshon/bounded_pool_executor
    import concurrent.futures

    name = 'bounded_pool_executor'

    class _BoundedPoolExecutor:
        semaphore = None

        def acquire(self):
            self.semaphore.acquire()

        def release(self, fn):
            self.semaphore.release()

        def submit(self, fn, *args, **kwargs):
            self.acquire()
            future = super().submit(fn, *args, **kwargs)
            future.add_done_callback(self.release)

            return future

    class BoundedProcessPoolExecutor(_BoundedPoolExecutor, concurrent.futures.ProcessPoolExecutor):

        def __init__(self, max_workers=None):
            super().__init__(max_workers)
            self.semaphore = multiprocessing.BoundedSemaphore(max_workers)

    class BoundedThreadPoolExecutor(_BoundedPoolExecutor, concurrent.futures.ThreadPoolExecutor):

        def __init__(self, max_workers=None):
            super().__init__(max_workers)
            self.semaphore = threading.BoundedSemaphore(max_workers)

    with BoundedProcessPoolExecutor(3) as executor:
        for i in range(100):
            executor.submit(func_to_process, i)
            print('Work #{} submitted'.format(i))


def solution_map_1():
    # https://github.com/mowshon/bounded_pool_executor
    import concurrent.futures

    name = 'bounded_pool_executor'

    class _BoundedPoolExecutor:
        semaphore = None

        def acquire(self):
            self.semaphore.acquire()

        def release(self, fn):
            self.semaphore.release()

        def submit(self, fn, *args, **kwargs):
            self.acquire()
            future = super().submit(fn, *args, **kwargs)
            future.add_done_callback(self.release)

            return future

    class BoundedProcessPoolExecutor(_BoundedPoolExecutor, concurrent.futures.ProcessPoolExecutor):

        def __init__(self, max_workers=None):
            super().__init__(max_workers)
            self.semaphore = multiprocessing.BoundedSemaphore(max_workers)

    class BoundedThreadPoolExecutor(_BoundedPoolExecutor, concurrent.futures.ThreadPoolExecutor):

        def __init__(self, max_workers=None):
            super().__init__(max_workers)
            self.semaphore = threading.BoundedSemaphore(max_workers)

    with BoundedProcessPoolExecutor(3) as executor:
        executor.map(func_to_process, range(15))
        print('All works submitted')
